{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a446e0a6-73f1-4635-948a-978740e5f665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "\n",
    "def Combine_All_Years(database_path, datasets = None, stations = None):\n",
    "    '''This is a function that combines all yearly Formatted, Filtered or Cleaned .csv files for \n",
    "    each station into one single .csv.\n",
    "    \n",
    "    :param str database_path: the path to the database\n",
    "    :param list datasets: a list of datasets to combine ('Formatted', 'Filtered' or 'Cleaned'). Leave as None to collect all stations.\n",
    "    :param list datasets: a list of stations to combine. Leave as None to collect all stations.\n",
    "    '''\n",
    "    os.chdir(database_path)\n",
    "    if not bool(datasets):\n",
    "        datasets = [f for f in os.listdir() if f.endswith('_Data') and not f.startswith('Raw')]\n",
    "\n",
    "    for dataset in datasets:\n",
    "        try:\n",
    "            os.chdir(dataset)\n",
    "        except:\n",
    "            raise ValueError(f'Unrecognised dataset path: {dataset}')\n",
    "            \n",
    "        if not bool(stations):\n",
    "            stations = [f for f in os.listdir() if f.endswith('_Hourly') or f.endswith('_Daily')and not f.startswith('.')]\n",
    "\n",
    "        for station in stations:\n",
    "            try:\n",
    "                os.chdir(station)\n",
    "            except:\n",
    "                raise ValueError(f'Unrecognised station path: {station}')\n",
    "            print('Combining '+ dataset+': '+station+'             ', end='\\r')\n",
    "            files = [f for f in os.listdir() if f.endswith('.csv')]\n",
    "\n",
    "            out = pd.DataFrame()\n",
    "\n",
    "            for f in files:\n",
    "                out = pd.concat([out,pd.read_csv(f)])\n",
    "\n",
    "            out = out[~out.Time.duplicated(keep='first')] \n",
    "\n",
    "            os.chdir('..')\n",
    "\n",
    "            out.to_csv(station+'.csv', index=False)\n",
    "\n",
    "        os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d6dec6-5da0-4815-855a-e10772dc04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_metadata(database_path):\n",
    "    '''Updates an existing metadata .csv file to include most current data availability for each station.\n",
    "    \n",
    "    :param str database_path: the database directory, containing a Metadata.csv file with sation names and information.\n",
    "    '''\n",
    "    os.chdir(database_path)\n",
    "    metadata = pd.read_csv('Metadata.csv')\n",
    "    \n",
    "    os.chdir('Formatted_Data')\n",
    "    \n",
    "    stations = metadata.Station_Name\n",
    "    metadata.index = metadata.Station_Name\n",
    "    for station in stations:\n",
    "        try:\n",
    "            data = pd.read_csv(station+'.csv')\n",
    "        except:\n",
    "            print(f'{station} not in database.')\n",
    "            continue\n",
    "        if station.endswith('Hourly'):\n",
    "            data.Time = pd.to_datetime(data.Time, format='%Y-%m-%d %H:%M:%S')\n",
    "        elif station.endswith('Daily'):\n",
    "            try:\n",
    "                data.Time = pd.to_datetime(data.Time, format='%Y-%m-%d %H:%M' %p)\n",
    "            except:\n",
    "                try:\n",
    "                    data.Time = pd.to_datetime(data.Time, format='%Y-%m-%d %H:%M')\n",
    "                except:\n",
    "                    try:\n",
    "                        data.Time = pd.to_datetime(data.Time, format='%Y-%m-%d')\n",
    "                    except:\n",
    "                        raise ValueError(f\"{station}'s datetime format is not recognised\")\n",
    "        print(f'Updated station: {station}')\n",
    "        tmin = data.Time.min()\n",
    "        tmax = data.Time.max()\n",
    "        metadata.loc[station, 'Time_Available'] = f'{tmin}, {tmax}'\n",
    "        metadata.loc[station, 'Data_Available'] = str(data.columns.to_list())\n",
    "    metadata.to_csv(database_path+'/Metadata.csv',index=False)\n",
    "    os.chdir(database_path)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a50dd4f8-c583-4085-b308-6b080941cb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining Filtered_Data: ArthursEWS_Daily                            \r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognised station path: ArthursEWS_Hourly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25088/2929383072.py\u001b[0m in \u001b[0;36mCombine_All_Years\u001b[1;34m(database_path, datasets, stations)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'ArthursEWS_Hourly'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25088/1545889276.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCombine_All_Years\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Formatted_Data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Filtered_Data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mupdate_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25088/2929383072.py\u001b[0m in \u001b[0;36mCombine_All_Years\u001b[1;34m(database_path, datasets, stations)\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Unrecognised station path: {station}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Combining '\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstation\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'             '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognised station path: ArthursEWS_Hourly"
     ]
    }
   ],
   "source": [
    "Combine_All_Years(os.getcwd(), datasets = ['Formatted_Data','Filtered_Data'])\n",
    "update_metadata(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f136b1b-1cca-412c-8bce-eb3e0583949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame()\n",
    "for f in files:\n",
    "    out = pd.concat([out,pd.read_csv('Formatted_Data/Chilton_Hourly/'+f)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42499d43-c156-49d1-8cf8-372fb3757ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68a536b9-1e9b-4848-a778-0b73c9014cd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expanduser() missing 1 required positional argument: 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25460/174396370.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: expanduser() missing 1 required positional argument: 'path'"
     ]
    }
   ],
   "source": [
    "os.path.expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a41674ae-eaba-4de2-a954-e616a5f4b3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints_Daily',\n",
       " 'ArthursAWS_ScreenObs_Hourly',\n",
       " 'ArthursCombined_Daily',\n",
       " 'ArthursEWS_Hourly',\n",
       " 'ArthursRain_Daily',\n",
       " 'ArthursTemps_Daily',\n",
       " 'BealeyRain_Daily',\n",
       " 'BrokenRiverCombined_Daily',\n",
       " 'BrokenRiverRain_Daily',\n",
       " 'BrokenRiverTemp_Daily',\n",
       " 'CampStreamCombined_Daily',\n",
       " 'CampStreamRain_Daily',\n",
       " 'CarringtonRain_Daily',\n",
       " 'Cass_Daily',\n",
       " 'Cass_Hourly',\n",
       " 'CastleHillRain_Daily',\n",
       " 'Chilton_Daily',\n",
       " 'Chilton_Hourly',\n",
       " 'ClifloArthursRain_Daily',\n",
       " 'CragieburnForestCombined_Daily',\n",
       " 'CragieburnForestTemps_Daily',\n",
       " 'CragieburnStnRain_Daily',\n",
       " 'EskRain_Daily',\n",
       " 'FlockhillRain_Daily',\n",
       " 'GrasmereRain_Daily',\n",
       " 'MtWhiteRain_Daily',\n",
       " 'OldCassRain_Daily']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f for f in os.listdir() if f.endswith('_Hourly') or f.endswith('_Daily')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b50691-aa36-4ea4-9ac2-4de72aae1999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
